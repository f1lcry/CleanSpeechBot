# CleanSpeechBot

Telegram-бот для локальной обработки голосовых сообщений и выдачи отформатированного текста. Он работает как в личных чатах, так и в группах: в приватных диалогах бот сразу присылает саммари, а в группах сохраняет голосовое, показывает кнопку «Сделать саммари» и запускает пайплайн только после ручного подтверждения. README служит единым источником правды о проекте: архитектура, пайплайн, требования, статус реализации и планы.

## Глобальная идея

Бот принимает голосовые сообщения от пользователей, локально конвертирует и транскрибирует аудио, а затем передаёт полученный текст локальной модели Llama 3.1 8B (через Ollama) для очистки и лёгкой суммаризации. Весь пайплайн полностью офлайн: никакие внешние API не используются, поэтому приватность пользователей гарантируется даже в продакшене.

## Архитектура и основные компоненты

- **Aiogram 3.x бот** — точка входа `bot/main.py` поднимает `Dispatcher`, регистрирует обработчики и управляет очередью задач.
- **Handlers** — маршруты `group_router`, `text_router` и `voice_router` в `bot/handlers/` принимают команды, обновления `chat_member` и голосовые вложения, валидируют контент и делегируют работу пайплайну.
- **Служебные утилиты**
  - `bot/utils/audio.py`: нормализация и валидация аудио через FFmpeg.
  - `bot/utils/whisper_engine.py`: обёртка над openai-whisper с гибкой настройкой SSL, устройств и кэша моделей.
  - `bot/utils/formatting_llm.py`: клиент Ollama, отвечающий за форматирование и суммаризацию.
  - `bot/utils/workers.py`: менеджер очередей и фоновых воркеров на asyncio.
- **Pipeline** — `bot/services/pipeline.py` связывает все модули в единую цепочку и управляет жизненным циклом задач (скачивание, конвертация, транскрибация, форматирование, ответ пользователю, очистка временных файлов).
- **Логирование** — `bot/services/logger.py` формирует единый формат логов, используется ботом и CLI.
- **CLI-инструменты** — `tools/` содержит автономные скрипты для локальной отладки конвертации, транскрибации и форматирования.

## Поведение в чатах

- **Добавление в группу.** Как только бот становится участником (`my_chat_member` → `member/administrator`), он отправляет приветствие с подсказками по кнопке «Сделать саммари» и напоминает, что в приватных чатах ответы приходят сразу.
- **Команда `/start`.** В личных сообщениях бот здоровается и просит прислать голосовое, а в группах ограничивается коротким служебным описанием без приветствия.
- **Голосовые в группах.** Сообщение скачивается и откладывается в память. Под голосовым появляется кнопка «Сделать саммари». Пока её не нажмут, файл не обрабатывается; повторные нажатия и устаревшие кнопки возвращают понятное сообщение. Для защиты диска действует автоматическая очистка: если никто не нажал кнопку несколько минут, запись и временный файл удаляются.
- **Личные диалоги.** Поведение осталось прежним: голосовые обрабатываются сразу после загрузки, без кнопок и задержек.

## Стек технологий

- **Язык:** Python 3.10+
- **Фреймворк бота:** Aiogram 3.x
- **Аудио-конвертация:** FFmpeg (OGG/MP3 → WAV)
- **Транскрибация:** openai-whisper (локальный inference)
- **LLM:** Ollama + Llama 3.1 8B (GGUF)
- **Асинхронность и очередь задач:** asyncio
- **Инфраструктура:** Docker, docker-compose, systemd (fallback), Ubuntu 22.04 LTS, Timeweb Cloud (4 vCPU / 8 GB RAM / 40 GB SSD)

## Структура репозитория

```
project_root/
├── bot/
│   ├── main.py                # Точка входа для запуска бота
│   ├── config.py              # Конфигурация и чтение переменных окружения
│   ├── handlers/              # Aiogram-хэндлеры
│   │   ├── group_handler.py   # Реакция на добавление бота в группы
│   │   ├── voice_handler.py   # Обработка голосовых сообщений
│   │   └── text_handler.py    # Обработка команд и служебных текстов
│   ├── utils/                 # Вспомогательные модули
│   │   ├── audio.py           # Работа с аудио (конвертация, валидация)
│   │   ├── whisper_engine.py  # Обёртка над Whisper
│   │   ├── formatting_llm.py  # Взаимодействие с Ollama / Llama
│   │   └── workers.py         # Очереди задач и фоновые воркеры
│   └── services/
│       ├── pipeline.py        # Основной пайплайн обработки сообщений
│       └── logger.py          # Настройка логирования
├── models/
│   ├── whisper_cache/         # Кэш / артефакты для Whisper
│   └── llama_prompts/         # Промпты и шаблоны для LLM
├── deployments/
│   ├── Dockerfile             # Сборка контейнера бота
│   ├── docker-compose.yml     # Композиция сервисов (бот, Ollama, пр.)
│   └── systemd/
│       └── bot.service        # Юнит для systemd как альтернатива docker-compose
├── .env                       # Переменные окружения (не в git)
├── requirements.txt           # Python-зависимости
├── test_files/                # Примеры аудио для отладки
└── README.md                  # Этот файл
```

## Логика пайплайна

1. **Приём голосового сообщения.** Aiogram получает сообщение и скачивает голосовое вложение.
2. **Постановка в очередь.** Файл отправляется в `TaskQueueManager`, чтобы ограничивать параллелизм и нагрузку на CPU/GPU.
3. **Обработка в `VoicePipeline`:**
   - Конвертация входного аудио (OGG/MP3/WAV) в унифицированный WAV с помощью FFmpeg.
   - Транскрибация файла локальным Whisper (openai-whisper) с кэшированием моделей на диске.
   - Форматирование, очистка и лёгкая суммаризация текста через локальную модель Llama 3.1 8B, поднятую в Ollama.
4. **Ответ пользователю.** Отформатированный текст отправляется обратно в чат (бот умеет делить длинный ответ на несколько сообщений).
5. **Уборка и логирование.** Временные файлы удаляются, ошибки фиксируются в логах и, при необходимости, триггерят fallback-сценарии.

## Безопасность, приватность и Stream Processing

Проект строится вокруг принципа «stream processing»: данные проходят через сервис конвейером (вход → обработка → ответ → уничтожение) и не хранятся дольше, чем требуется для конкретной задачи. README фиксирует, что бот работает **исключительно на локальных моделях** (Whisper + Llama 3.1 8B через Ollama), не отправляет данные во внешние API и не сохраняет пользовательские аудио, транскрипты или историю переписки.

- **Аудио:**
  - Загруженные файлы сохраняются только во временных локациях (RAM или `/tmp`).
  - После конвертации и транскрибации любой файл немедленно удаляется; использование постоянных томов или бэкапов с пользовательским контентом запрещено.
- **Транскрипты:**
  - Текст живёт только в оперативной памяти в рамках задачи.
  - После отправки ответа пользователю текст полностью уничтожается и не попадает ни в файлы, ни в БД, ни в логи.
- **База данных:**
  - Пока отсутствует; планируется хранить только технические метаданные: `chat_id` (желательно захешированный с солью), анонимизированный `user_id`, настройки чата, счётчики запросов.
  - История сообщений, аудио, транскрипты и любой пользовательский контент запрещены к сохранению.
- **Кэш:**
  - Кэширование аудио и транскриптов отсутствует; допускаются только временные структуры данных в памяти (например, `asyncio.Queue`).
  - Если нужен кратковременный кэш ради оптимизации, он ограничен временем жизни процесса и никогда не записывается на диск.
- **Логирование:**
  - Логи содержат исключительно технические события (`voice_received`, `transcription_success`, `llm_error` и т. п.), UUID задач, длительность обработки, размеры файлов и тайминги этапов.
  - Текст пользовательских сообщений, имена, raw JSON обновлений Telegram и любые транскрипты логировать запрещено.
- **Прозрачность и доверие:**
  - README фиксирует, что после обработки на диске не остаётся следов данных, а вся обработка выполняется офлайн локальными моделями.
  - Ротация логов возможна стандартными средствами, но без сохранения пользовательского контента.

## Функциональные требования к пайплайну

- Конвертация входного аудио (OGG/MP3/WAV) в единый формат для Whisper.
- Локальная транскрибация Whisper без внешних API.
- Запросы к Ollama API с локально развёрнутой Llama 3.1 8B.
- Очистка и структурирование текста: абзацы, пунктуация, удаление шумов.
- Очередь задач поверх asyncio для контроля нагрузки.
- Обработка ошибок, ретраи, fallback-ответы пользователю.
- Очистка временных файлов и контроль ограничений по длине аудио.
- Корректная работа с длинными сообщениями (разбиение, потоковая обработка, ограничения Telegram).

## Настройка окружения

1. **Системные требования**
   - Ubuntu 22.04 LTS
   - 4 vCPU / 8 GB RAM / 40 GB SSD (Timeweb Cloud)

2. **Предварительная установка**
   - Python 3.10+
   - FFmpeg (должен быть доступен в `$PATH`)
   - GPU-драйверы/CUDA Toolkit, если планируется использовать `--device cuda` в Whisper
   - Docker и docker-compose
   - Ollama (для запуска Llama 3.1 8B)
   - Whisper модельные файлы (скачивание при первом запуске)

3. **Переменные окружения (`.env`)**

   ```env
   BOT_TOKEN=<telegram-bot-token>
   OLLAMA_HOST=http://localhost:11434
   # Настройка форматирования/LLM
   FORMATTER_MODEL=llama3.1:8b
   FORMATTER_TIMEOUT=120
   FORMATTER_PROMPT_SOURCE=file
   FORMATTER_PROMPT_PATH=models/llama_prompts/formatter_system_prompt.txt
   # FORMATTER_PROMPT_TEXT=""  # Используется, если FORMATTER_PROMPT_SOURCE=inline

   # Whisper и аудио
   WHISPER_MODEL=medium
   WHISPER_LANGUAGE=ru
   WHISPER_TEMPERATURE=0.0
   WHISPER_DEVICE=cpu
   WHISPER_CACHE_DIR=./models/whisper_cache
   WHISPER_CA_BUNDLE=/etc/ssl/certs/corporate-ca.pem
   WHISPER_INSECURE_SSL=false
   AUDIO_TMP_DIR=/tmp/cleanspeechbot
   TASK_QUEUE_LIMIT=2
   ```

4. **Установка зависимостей**

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

   `requirements.txt` тянет все необходимые Python-библиотеки: `aiogram`, `python-dotenv`, `ollama`, а также аудио-стек (`openai-whisper==20250625`, `torch==2.1.2`, `numpy<2`). Whisper подгружается локально — модель скачивается автоматически в директорию кэша при первом запуске. Если корпоративная сеть подменяет SSL-сертификаты, укажите путь к корневому сертификату через `WHISPER_CA_BUNDLE` (или CLI-параметр `--ca-bundle`). В крайнем случае доступно отключение проверки (`WHISPER_INSECURE_SSL=true` или `--insecure-ssl`).

5. **Запуск в разработке**

   ```bash
   cd bot
   python main.py
   ```

6. **Запуск через Docker Compose**

   ```bash
   docker-compose up --build
   ```

## Модуль конвертации

Для локальной отладки конвертации добавлен CLI `tools/convert_audio.py`, который использует те же правила, что и бот. Все CLI автоматически подхватывают `.env` через `tools/_env.py`, поэтому можно задавать переменные один раз.

- **Системные требования**: Python 3.10+, установленный FFmpeg, доступный в `$PATH`.
- **Аргументы CLI**:
  - `--input` — путь к исходному `.ogg`/`.mp3` (обязательный).
  - `--output-dir` — каталог назначения (по умолчанию `AUDIO_TMP_DIR`).
  - `--output-name` — имя выходного файла без расширения.
  - `--validate` — выполнить проверку параметров WAV после конвертации.
- **Переменные окружения**:
  - `AUDIO_TMP_DIR` — базовый каталог для временных WAV.
- **Пример**:

  ```bash
  python tools/convert_audio.py --input test_files/voice_message.ogg --validate
  ```

## Модуль транскрибации

CLI `tools/transcribe_audio.py` оборачивает `WhisperEngine` и использует те же настройки, что и продакшен.

- **Аргументы CLI**:
  - `--input` — путь к WAV. Если не указан, берётся последний файл в `--tmp-dir`.
  - `--tmp-dir` — где лежат WAV (по умолчанию `AUDIO_TMP_DIR`).
  - `--model`, `--language`, `--temperature`, `--device` — пробрасываются в Whisper.
  - `--ca-bundle`, `--insecure-ssl` — настройки TLS для скачивания модели.
  - `--verbose` — расширенное логирование.
- **Переменные окружения**:
  - `AUDIO_TMP_DIR`, `WHISPER_MODEL`, `WHISPER_LANGUAGE`, `WHISPER_DEVICE`, `WHISPER_CACHE_DIR`, `WHISPER_CA_BUNDLE`, `WHISPER_INSECURE_SSL`.
- **Примеры**:

  ```bash
  python tools/transcribe_audio.py
  python tools/transcribe_audio.py --input /tmp/cleanspeechbot/voice.wav --language ru --device cpu
  ```

## Модуль форматирования

`tools/format_text.py` позволяет локально проверить работу `FormattingLLMClient` без запуска Telegram-бота.

- **Требования**: запущенный Ollama с нужной моделью и доступ к файлу системного промпта.
- **Аргументы CLI**:
  - Источник транскрипта: `--text`, `--input-file` или stdin.
  - `--host`, `--model` — переопределяют `OLLAMA_HOST`/`FORMATTER_MODEL`.
  - `--prompt`/`--prompt-file` — временно подменяют системный промпт.
  - `--timeout` — таймаут запроса в секундах (по умолчанию `FORMATTER_TIMEOUT`).
  - `--verbose` — подробные логи и прогресс стриминга.
- **Переменные окружения**:
  - `OLLAMA_HOST`, `FORMATTER_MODEL`, `FORMATTER_TIMEOUT`, `FORMATTER_PROMPT_SOURCE`, `FORMATTER_PROMPT_PATH`, `FORMATTER_PROMPT_TEXT`.
- **Пример**:

  ```bash
  python tools/format_text.py --text "привет это тест" --verbose
  python tools/format_text.py --input-file transcript.txt --prompt-file models/llama_prompts/formatter_system_prompt.txt
  ```

CLI выводит только отформатированный текст. При ошибке взаимодействия с Ollama команда вернёт код `1` и сообщение вида `Formatting failed: ...`.

## Очередь задач и производительность

- Очередь реализована в `bot/utils/workers.py`, управляется через asyncio.
- Ограничиваем количество параллельных транскрибаций и запросов к LLM, чтобы не перегружать CPU.
- Настройка размеров очереди и числа воркеров через переменные окружения / конфиг.
- Пайплайн устойчив к отменам и перезапускам: при остановке бота очередь дожидается завершения всех задач, чтобы не потерять сообщения.
- План на будущее: добавить метрики обработки, мониторинг времени выполнения и использование ресурсов.

## Логирование и мониторинг

- `bot/services/logger.py` — единая точка настройки логов (уровни, формат, вывод в файл/консоль).
- Логи ошибок и исключений позволяют анализировать сбои пайплайна.
- Возможные улучшения: интеграция с systemd journal, ротация логов, отдельный лог-бот/канал, уведомления.

## Каталог `models/`

- `whisper_cache/` — кэшированные модели и данные Whisper для ускорения старта.
- `llama_prompts/` — промпты для форматирования текста, шаблоны ответов, системные инструкции.

## Развёртывание

- Основной сценарий: docker-compose с сервисами бота и Ollama.
- Альтернатива: systemd-юнит `deployments/systemd/bot.service` при запуске напрямую.
- Автоматизация обновлений: `git pull`, рестарт сервиса, миграция моделей.
- Бэкапы: периодическое копирование `models/` и логов.

## Документация и полезные ссылки

- [Aiogram 3.x](https://docs.aiogram.dev/en/latest/)
- [Whisper (openai-whisper)](https://github.com/openai/whisper)
- [FFmpeg](https://ffmpeg.org/documentation.html)
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Llama 3.1 (Meta)](https://huggingface.co/meta-llama)
- [Docker](https://docs.docker.com/)
- [docker-compose](https://docs.docker.com/compose/)
- [systemd](https://www.freedesktop.org/software/systemd/man/systemd.service.html)
- [Timeweb Cloud](https://timeweb.cloud/docs)

## TODO / идеи на будущее

Приоритеты сформированы исходя из текущего состояния (бот работает в личных сообщениях) и дальнейших планов владельца проекта:

1. **Интеграция в групповые чаты Telegram.**
   - Хендлеры должны корректно работать в группах/супергруппах, различать нескольких пользователей и поддерживать командную работу.
2. **Отдельный лог-бот или лог-чат.**
   - Вести технические логи в отдельном приватном канале/боте для продакшен-развёртывания.
3. **База данных пользователей и чатов.**
   - Отслеживать уникальных пользователей, количество запросов и формат взаимодействия для аналитики и лимитов.
4. **Расширенная аналитика и метрики.**
   - Счётчики задач, длительность этапов, прогресс-статусы для пользователя, уведомления об ошибках.
5. **Подписочная модель и платежи.**
   - Добавить планы подписок (например, месячная безлимитная) и интегрировать разные платёжные каналы: СБП, Telegram Stars/TON, локальные провайдеры.
6. **CI/CD, тесты, мониторинг.**
   - Юнит-тесты пайплайна, мокирование Whisper/LLM, автоматические проверки, алерты.

Любые дополнения по ходу разработки фиксируем здесь, чтобы Codex имел доступ к свежему контексту.

## Статус реализации (на текущий момент)

- Реализованы и интегрированы три ключевых модуля (конвертация аудио, транскрибация Whisper, форматирование LLM) и основной `VoicePipeline`.
- Бот полностью работает в личных сообщениях Telegram, поддерживает очереди задач и корректно обрабатывает отмены/перезапуски.
- CLI-инструменты позволяют отдельно тестировать каждый модуль пайплайна.

## Change Log

| Период / PR | Краткое описание |
| --- | --- |
| `f9080ac` – `#1` | Первичная документация: контекст проекта, описание идеи, требования. |
| `43cab95` – `#2` | Скелет проекта, конфигурации, сервисы-заглушки, начальная структура каталогов. |
| `030666f` – `#3` | Политика безопасности и stream processing, расширение README. |
| `90882ab` – `#5` | Модуль конвертации аудио, CLI и тестовые файлы. |
| `af598e4` – `#6` | WhisperEngine и инструменты транскрибации, гибкие настройки SSL. |
| `416f754` – `#7` | Срочное исправление CLI транскрибации (корректные пути и tmp dir). |
| `54de56f` – `#8` | Клиент форматирования через Ollama, CLI, env-хелперы и tooling. |
| `427d32b` – `#9` | Финальный голосовой пайплайн: TaskQueueManager, VoicePipeline, end-to-end обработка голосовых сообщений. |

## License

Apache License 2.0. См. файл [LICENSE](./LICENSE) для полного текста. Код можно использовать и модифицировать при условии сохранения уведомления об авторстве и лицензии во всех копиях и производных работах.
